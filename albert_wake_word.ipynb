{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "from tqdm.notebook import tqdm\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2  # Add this line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#convert from opus to wav\n",
    "def convert_opus_to_wav(directory):\n",
    "    for root, dirs, files in tqdm(os.walk(directory)):\n",
    "        for file in files:\n",
    "            if file.endswith(\".opus\"):\n",
    "                opus_path = os.path.join(root, file)\n",
    "                wav_path = os.path.splitext(opus_path)[0] + \".wav\"\n",
    "                audio = AudioSegment.from_file(opus_path, format=\"opus\")\n",
    "                audio.export(wav_path, format=\"wav\")\n",
    "\n",
    "#resample wav files to 16kHz\n",
    "def resample_wav_files(directory):\n",
    "    for root, dirs, files in tqdm(os.walk(directory)):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                wav_path = os.path.join(root, file)\n",
    "                audio = AudioSegment.from_file(wav_path, format=\"wav\")\n",
    "                audio = audio.set_frame_rate(16000)\n",
    "                audio.export(wav_path, format=\"wav\")\n",
    "\n",
    "#Change .wav subtype to PCM_16\n",
    "def change_wav_subtype(directory):\n",
    "    for root, dirs, files in tqdm(os.walk(directory)):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                wav_path = os.path.join(root, file)\n",
    "                audio = AudioSegment.from_file(wav_path, format=\"wav\")\n",
    "                audio.export(wav_path, format=\"wav\", subtype=\"PCM_16\")\n",
    "\n",
    "\n",
    "def process_wav_duration(directory):\n",
    "    for root, dirs, files in tqdm(os.walk(directory)):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                wav_path = os.path.join(root, file)\n",
    "                audio = AudioSegment.from_file(wav_path, format=\"wav\")\n",
    "                duration = len(audio) / 1000  # duration in seconds\n",
    "\n",
    "                if duration < 1 and duration != 0:\n",
    "                    audio = audio + AudioSegment.silent(duration=1000 - duration * 1000)\n",
    "                elif duration > 1:\n",
    "                    audio = audio[:1000]\n",
    "\n",
    "                audio.export(wav_path, format=\"wav\")\n",
    "\n",
    "#split audio into 1 second chunks\n",
    "def split_audio_chunks(file_path, output_dir, chunk_length_ms=1000):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "\n",
    "    # Calculate the number of chunks\n",
    "    num_chunks = len(audio) // chunk_length_ms\n",
    "\n",
    "    # Split the audio and save each chunk\n",
    "    for i in range(num_chunks):\n",
    "        chunk = audio[i*chunk_length_ms:(i+1)*chunk_length_ms]\n",
    "\n",
    "        # Only save the chunk if it's at least 1 second long\n",
    "        if len(chunk) >= chunk_length_ms:\n",
    "            chunk_path = os.path.join(output_dir, f\"{os.path.basename(file_path).rsplit('.', 1)[0]}_chunk{i}.wav\")\n",
    "            chunk.export(chunk_path, format=\"wav\")\n",
    "            print(f\"Saved chunk to: {chunk_path}\")\n",
    "\n",
    "def process_directory_chunks(input_directory, output_directory):\n",
    "    for root, dirs, files in tqdm(os.walk(input_directory)):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                output_dir = os.path.join(output_directory, os.path.basename(file_path).rsplit('.', 1)[0])\n",
    "\n",
    "                # Create the output directory if it doesn't exist\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "                split_audio_chunks(file_path, output_dir)\n",
    "\n",
    "\n",
    "def overlay_random_wav(source_dir_1, source_dir_2, target_dir, volume_dB=-20, repeat=None):\n",
    "    skipped_files = 0\n",
    "    wav_files_1 = []\n",
    "    wav_files_2 = []\n",
    "\n",
    "    # Collect all .wav files in the source directories and their subdirectories\n",
    "    for root, dirs, files in os.walk(source_dir_1):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                wav_files_1.append(os.path.join(root, file))\n",
    "\n",
    "    for root, dirs, files in os.walk(source_dir_2):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                wav_files_2.append(os.path.join(root, file))\n",
    "\n",
    "    # Process each file in the first directory\n",
    "    for file_1 in tqdm(wav_files_1, desc=\"Processing files\"):\n",
    "        # Load the file\n",
    "        audio_1 = AudioSegment.from_file(file_1)\n",
    "\n",
    "        # Check if the file is exactly 1 second long\n",
    "        if len(audio_1) != 1000:\n",
    "            print(f\"Skipped file: {file_1} (length is not 1 second)\")\n",
    "            skipped_files += 1\n",
    "            continue\n",
    "\n",
    "        # Repeat for the specified number of times, or once if no repeat count is provided\n",
    "        for i in range(repeat if repeat is not None else 1):\n",
    "            # Pick a random file from the second directory\n",
    "            while True:\n",
    "                file_2 = random.choice(wav_files_2)\n",
    "                audio_2 = AudioSegment.from_file(file_2)\n",
    "\n",
    "                # Check if the random file is exactly 1 second long\n",
    "                if len(audio_2) == 1000:\n",
    "                    break\n",
    "\n",
    "            # Mix the random file into the first file at the specified volume\n",
    "            mixed_audio = audio_1.overlay(audio_2 + volume_dB)\n",
    "\n",
    "            # Save the mixed audio to the target directory\n",
    "            relative_path = os.path.relpath(file_1, source_dir_1)\n",
    "            target_file = os.path.join(target_dir, relative_path)\n",
    "\n",
    "            # If repeating, append the repeat count to the filename\n",
    "            if repeat is not None:\n",
    "                target_file = f\"{os.path.splitext(target_file)[0]}_{i}{os.path.splitext(target_file)[1]}\"\n",
    "\n",
    "            os.makedirs(os.path.dirname(target_file), exist_ok=True)\n",
    "            mixed_audio.export(target_file, format=\"wav\")\n",
    "\n",
    "    return skipped_files\n",
    "\n",
    "\n",
    "def create_spectrogram(audio_path, save_path):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Generate a spectrogram\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "    # Save the spectrogram as a numpy array\n",
    "    np.save(save_path, S)\n",
    "\n",
    "def process_dir_spectogram(input_dir, output_dir):\n",
    "    # Iterate over all files in input_dir and its subdirectories\n",
    "    for root, dirs, files in tqdm(os.walk(input_dir)):\n",
    "        for file in files:\n",
    "            # Check if the file is a .wav file\n",
    "            if file.endswith('.wav'):\n",
    "                # Compute the full path to the file\n",
    "                file_path =  os.path.join(root, file)\n",
    "        \n",
    "                # Generate a random 16 digit name\n",
    "                random_name = ''.join(random.choices(string.ascii_letters + string.digits, k=16))\n",
    "                \n",
    "                # Compute the output path\n",
    "                output_path = os.path.join(output_dir, random_name + '.npy')\n",
    "                \n",
    "                # Create a spectrogram and save it to the output path\n",
    "                create_spectrogram(file_path, output_path)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wake_word_dir = \"\"\n",
    "not_wake_word_dir = \"\"\n",
    "\n",
    "background_noise_dir = \"\"\n",
    "background_noise_chunks_dir = \"\"\n",
    "\n",
    "wake_word_with_noise_dir = \"\"\n",
    "not_wake_word_with_noise_dir = \"\"\n",
    "\n",
    "wake_word_spectrogram_dir = \"\"\n",
    "not_wake_word_spectrogram_dir = \"\"\n",
    "\n",
    "# Convert all .opus files to .wav\n",
    "print(\"Converting .opus files to .wav\")\n",
    "convert_opus_to_wav(wake_word_dir)\n",
    "convert_opus_to_wav(not_wake_word_dir)\n",
    "convert_opus_to_wav(background_noise_dir)\n",
    "\n",
    "#Convert all wav files to 16kHz\n",
    "print(\"Resampling .wav files to 16kHz\")\n",
    "resample_wav_files(wake_word_dir)\n",
    "resample_wav_files(not_wake_word_dir)\n",
    "resample_wav_files(background_noise_dir)\n",
    "\n",
    "#Change .wav subtype to PCM_16\n",
    "print(\"Changing .wav subtype to PCM_16\")\n",
    "change_wav_subtype(wake_word_dir)\n",
    "change_wav_subtype(not_wake_word_dir)\n",
    "change_wav_subtype(background_noise_dir)\n",
    "\n",
    "# Process the audio files to be exactly 1 second long\n",
    "print(\"Processing audio files to be exactly 1 second long\")\n",
    "process_wav_duration(wake_word_dir)\n",
    "process_wav_duration(not_wake_word_dir)\n",
    "\n",
    "# Split the audio files into 1 second chunks\n",
    "print(\"Splitting audio files into 1 second chunks\")\n",
    "process_directory_chunks(background_noise_dir, background_noise_chunks_dir)\n",
    "\n",
    "# Overlay random background noise into the wake word files\n",
    "print(\"Overlaying random background noise into the wake word files\")\n",
    "overlay_random_wav(background_noise_chunks_dir, wake_word_dir, wake_word_with_noise_dir, repeat=170)\n",
    "overlay_random_wav(background_noise_chunks_dir, not_wake_word_dir, not_wake_word_with_noise_dir, repeat=0)\n",
    "\n",
    "#create spectrogram\n",
    "print(\"Creating spectrograms\")\n",
    "process_dir_spectogram(wake_word_with_noise_dir, wake_word_spectrogram_dir)\n",
    "process_dir_spectogram(not_wake_word_with_noise_dir, not_wake_word_spectrogram_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spectrograms and create the labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for folder in [wake_word_spectrogram_dir, not_wake_word_spectrogram_dir]:\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith('.npy'):\n",
    "            spectrogram = np.load(os.path.join(folder, file))\n",
    "            data.append(spectrogram)\n",
    "            labels.append(1 if os.path.basename(folder) == 'wake_word' else 0)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Reshape the data to fit the model\n",
    "data = data.reshape((-1, data.shape[1], data.shape[2], 1))\n",
    "\n",
    "# Assuming data is your feature set and labels is your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.05, random_state=42)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Define a function to create the model, required for KerasClassifier\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01), input_shape=(data.shape[1], data.shape[2], 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier with KerasClassifier\n",
    "model = create_model()\n",
    "\n",
    "# Perform cross-validation\n",
    "history = model.fit(data, labels, epochs=10, batch_size=10, verbose=2, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"working_model_1\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
